{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGaHmRh1pQzd"
      },
      "source": [
        "# **Exercise 0: Preprocessing Text Data on 20newsgroups Dataset**\n",
        "\n",
        "\n",
        "1.   Remove punctuation, stop-words\n",
        "2.   Bag-of-words feature representation\n",
        "3.   TF-IDF feature representation\n",
        "4.   Split the dataset randomly into train/validation/test splits 80%-10%-10%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3gD5oG4pQze"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import operator\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.utils import shuffle\n",
        "import math\n",
        "from sklearn.svm import SVC, NuSVC, LinearSVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "np.random.seed(3116)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGUtxBTZpQzf"
      },
      "outputs": [],
      "source": [
        "path20 = 'C:/Users/user/20_newsgroups/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-kgiEz8pQzg",
        "outputId": "d0e3bef5-0832-4ed3-c1d2-e35f3b2e57b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['sci.med', 'comp.graphics']\n"
          ]
        }
      ],
      "source": [
        "foldernames=sorted(os.listdir(os.path.join('C:/Users/user/20_newsgroups/')))\n",
        "categories = [13,1]    #index of required folder names\n",
        "foldernames = [foldernames[x] for x in categories]\n",
        "print(foldernames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQXxAyhTpQzh",
        "outputId": "a24020fd-6593-468e-c314-4016d5f74e27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "length of data 0 1000\n",
            "length of data 1 1000\n"
          ]
        }
      ],
      "source": [
        "data={}           #dict of foldernames (keys) -> f -> docs\n",
        "for f in foldernames:\n",
        "    data[f]=[]\n",
        "    for docs in os.listdir(os.path.join(path20,f)):\n",
        "        with open(os.path.join(path20,f,docs),encoding='latin-1') as doc_open:\n",
        "            data[f].append(doc_open.read())\n",
        "\n",
        "for i in range(len(data)):\n",
        "    print(\"length of data\",i,len(data[foldernames[i]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WNtL4MapQzh"
      },
      "source": [
        "## *Remove punctuation, stop-words*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qW9WhWevpQzi"
      },
      "outputs": [],
      "source": [
        "punctuation_list = list(punctuation)\n",
        "stop_words=stopwords.words('english')\n",
        "stop_words+=punctuation_list\n",
        "\n",
        "# Additinal stopwords as common and unnecessary words among documents\n",
        "stop_words += ['newsgroups:','sci.med','computer','graphics','comp.graphics','subject:','from:', 'lines:', 'path:', 'organization:', \n",
        "            'date:','would', 'writes:', 'references:','message-id:', 'article', 'sender:', 'nntp-posting-host:', 'people', \n",
        "            'university', 'think', 'xref:', 'cantaloupe.srv.cs.cmu.edu',  'could', 'distribution:', 'first', \n",
        "            'anyone', 'really', 'since', 'still', \"max>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MAQVs5opQzj"
      },
      "source": [
        "## *Bag-of-words feature representation*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MgRdA9BpQzj",
        "outputId": "c66dacdc-50c2-4221-b5f5-1e417cbeffe1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "18595\n"
          ]
        }
      ],
      "source": [
        "words_all={}                 #Bag of Words     (word and count dict)\n",
        "for i in range(len(data)):\n",
        "    for text in data[foldernames[i]]:\n",
        "        for w in text.split(): #words splitted in text document\n",
        "            if w.lower() not in stop_words and len(w.lower()) >= 4 and w.isalpha(): #conditions to considered as word\n",
        "                if w.lower() not in words_all:\n",
        "                    words_all[w.lower()]=1\n",
        "                else:\n",
        "                    words_all[w.lower()]+=1\n",
        "\n",
        "print(len(words_all))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwhifZyHpQzk",
        "outputId": "0b2b6e3b-053c-4314-b6d2-9751f19dbe68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('image', 1040), ('like', 886), ('also', 871), ('know', 821), ('many', 604)]\n"
          ]
        }
      ],
      "source": [
        "words_all_sorted = sorted(words_all.items(),key=lambda t: t[1], reverse = True)   #7040 words appear only 1 time\n",
        "print(words_all_sorted[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLjipbN6pQzl",
        "outputId": "c5eaee0b-780a-4401-9f39-398a356ac3ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Most common 5 words among documents are:  ['image', 'like', 'also', 'know', 'many']\n"
          ]
        }
      ],
      "source": [
        "word_list = []   #feature list\n",
        "#word_count = []\n",
        "for word, count in sorted(words_all.items(), key=lambda t: t[1], reverse=True):\n",
        "    word_list.append(word)\n",
        "\n",
        "print(\"Most common 5 words among documents are: \",word_list[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qw2PsahYpQzl"
      },
      "source": [
        "## *TF-IDF feature representation*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scAxC2i2pQzl"
      },
      "outputs": [],
      "source": [
        "data1 = data[foldernames[0]] + data[foldernames[1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPzkgLYlpQzm",
        "outputId": "a4dba50a-0c4c-4826-aeeb-9a255604c72e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[foldernames[1]][1] == data1[1001]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhL4Cy9upQzm",
        "outputId": "bcbd0ffc-3c19-4e8c-e562-c5e5683b95ba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ax', 'cantaloupe', 'cmu', 'comp', 'cs', 'date', 'distribution', 'edu', 'host', 'id', 'lines', 'max', 'med', 'message', 'newsgroups', 'nntp', 'organization', 'path', 'posting', 'references', 'sci', 'sender', 'srv', 'subject', 'writes', 'xref'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(2000, 18595)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf_idf_vector = TfidfVectorizer(stop_words=stop_words, vocabulary=word_list)\n",
        "tf_idfX = tf_idf_vector.fit_transform(data1)\n",
        "tf_idfX.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hKe1luapQzn"
      },
      "outputs": [],
      "source": [
        "tfidf_words = pd.DataFrame(tf_idfX.toarray(), columns=word_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtHQGVmupQzn",
        "outputId": "0a8dccc1-56ee-47bb-c401-e2cf4acf8c05"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>like</th>\n",
              "      <th>also</th>\n",
              "      <th>know</th>\n",
              "      <th>many</th>\n",
              "      <th>file</th>\n",
              "      <th>jpeg</th>\n",
              "      <th>available</th>\n",
              "      <th>medical</th>\n",
              "      <th>information</th>\n",
              "      <th>...</th>\n",
              "      <th>skylane</th>\n",
              "      <th>polyon</th>\n",
              "      <th>martens</th>\n",
              "      <th>ralcgm</th>\n",
              "      <th>gplot</th>\n",
              "      <th>allegories</th>\n",
              "      <th>hide</th>\n",
              "      <th>ginsberg</th>\n",
              "      <th>zheng</th>\n",
              "      <th>decor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.034327</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.052356</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.045559</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006198</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011959</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.063838</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.007936</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.046641</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.014999</td>\n",
              "      <td>0.019674</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.115359</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.029624</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.095283</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.105381</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>0.083751</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.058895</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.070188</td>\n",
              "      <td>0.030908</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.115889</td>\n",
              "      <td>0.317195</td>\n",
              "      <td>0.115889</td>\n",
              "      <td>0.115889</td>\n",
              "      <td>0.115889</td>\n",
              "      <td>0.109947</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.243498</td>\n",
              "      <td>0.243498</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows Ã— 18595 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         image      like      also      know      many      file  jpeg  \\\n",
              "0     0.000000  0.000000  0.000000  0.034327  0.000000  0.000000   0.0   \n",
              "1     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   0.0   \n",
              "2     0.000000  0.006198  0.000000  0.011959  0.000000  0.000000   0.0   \n",
              "3     0.000000  0.046641  0.000000  0.014999  0.019674  0.000000   0.0   \n",
              "4     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   0.0   \n",
              "...        ...       ...       ...       ...       ...       ...   ...   \n",
              "1995  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   0.0   \n",
              "1996  0.000000  0.000000  0.000000  0.029624  0.000000  0.095283   0.0   \n",
              "1997  0.083751  0.000000  0.000000  0.058895  0.000000  0.000000   0.0   \n",
              "1998  0.000000  0.000000  0.070188  0.030908  0.000000  0.000000   0.0   \n",
              "1999  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   0.0   \n",
              "\n",
              "      available  medical  information  ...   skylane    polyon   martens  \\\n",
              "0      0.052356      0.0     0.045559  ...  0.000000  0.000000  0.000000   \n",
              "1      0.000000      0.0     0.000000  ...  0.000000  0.000000  0.000000   \n",
              "2      0.063838      0.0     0.007936  ...  0.000000  0.000000  0.000000   \n",
              "3      0.000000      0.0     0.000000  ...  0.000000  0.000000  0.000000   \n",
              "4      0.000000      0.0     0.000000  ...  0.000000  0.000000  0.000000   \n",
              "...         ...      ...          ...  ...       ...       ...       ...   \n",
              "1995   0.000000      0.0     0.000000  ...  0.115359  0.000000  0.000000   \n",
              "1996   0.000000      0.0     0.000000  ...  0.000000  0.105381  0.000000   \n",
              "1997   0.000000      0.0     0.000000  ...  0.000000  0.000000  0.000000   \n",
              "1998   0.000000      0.0     0.000000  ...  0.000000  0.000000  0.115889   \n",
              "1999   0.000000      0.0     0.000000  ...  0.000000  0.000000  0.000000   \n",
              "\n",
              "        ralcgm     gplot  allegories      hide  ginsberg     zheng     decor  \n",
              "0     0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "1     0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "2     0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "3     0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "4     0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "...        ...       ...         ...       ...       ...       ...       ...  \n",
              "1995  0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "1996  0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "1997  0.000000  0.000000    0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "1998  0.317195  0.115889    0.115889  0.115889  0.109947  0.000000  0.000000  \n",
              "1999  0.000000  0.000000    0.000000  0.000000  0.000000  0.243498  0.243498  \n",
              "\n",
              "[2000 rows x 18595 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_TotCg1pQzn"
      },
      "source": [
        "## *Split the dataset randomly into train/validation/test splits 80%-10%-10*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFMQbHvdpQzn",
        "outputId": "8f6b3ee7-d539-4d48-e363-9cab9d50db08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.61980754  0.         ...  0.          0.\n",
            "   0.        ]\n",
            " ...\n",
            " [ 8.37509113  0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          7.01884416 ... 10.99472469  0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.         24.34977875\n",
            "  24.34977875]]\n"
          ]
        }
      ],
      "source": [
        "X=tfidf_words.values\n",
        "X *= 100  #work wth integers\n",
        "print(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUPO2QKbpQzo"
      },
      "outputs": [],
      "source": [
        "Y=[] # target newsgroup \n",
        "for i in range(len(data)):\n",
        "    for doc in data[foldernames[i]]:\n",
        "        Y.append(foldernames[i])\n",
        "Y=np.array(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "teystO7ypQzp",
        "outputId": "03ddf5ed-a804-439f-83e1-720600143806"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X dimension: (2000, 18595)\n",
            "Y dimension: (2000,)\n"
          ]
        }
      ],
      "source": [
        "print(\"X dimension:\", np.shape(X))\n",
        "print(\"Y dimension:\", np.shape(Y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yw9ruds7pQzp"
      },
      "outputs": [],
      "source": [
        "X, Y = shuffle(np.array(X), np.array(Y), random_state=3116)   #shuffle dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBa8ymDKpQzp"
      },
      "outputs": [],
      "source": [
        "def train(data,fraction1,fraction2): #To split dataset into train (80%), val (10%), test (10%)\n",
        "    n = len(data)\n",
        "    c=math.ceil((fraction1)*n)\n",
        "    d=math.ceil((fraction2)*n)\n",
        "    train = data[:c]\n",
        "    return train\n",
        "\n",
        "def val(data,fraction1,fraction2): #Validation data\n",
        "    n = len(data)\n",
        "    c=math.ceil((fraction1)*n)\n",
        "    d=math.ceil((fraction2)*n)\n",
        "    val = data[c:d]\n",
        "    return val\n",
        "\n",
        "def test(data,fraction1,fraction2): #Test data\n",
        "    n = len(data)\n",
        "    c=math.ceil((fraction1)*n)\n",
        "    d=math.ceil((fraction2)*n)\n",
        "    test = data[d:n]\n",
        "    return test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jm_CuLEpQzq"
      },
      "outputs": [],
      "source": [
        "trainX = train(X,0.8,0.9)\n",
        "trainY = train(Y,0.8,0.9)\n",
        "valX = val(X,0.8,0.9)\n",
        "valY = val(Y,0.8,0.9)\n",
        "testX = test(X,0.8,0.9)\n",
        "testY = test(Y,0.8,0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LHzQ-S8pQzq",
        "outputId": "8fae89d4-8417-4b3d-94b0-393cfea6a745"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: X: (1600, 18595) Y: (1600,)\n",
            "Validation: X: (200, 18595) Y: (200,)\n",
            "Test: X: (200, 18595) Y: (200,)\n"
          ]
        }
      ],
      "source": [
        "print(\"Train:\", \"X:\", np.shape(trainX), \"Y:\",np.shape(trainY))\n",
        "print(\"Validation:\", \"X:\", np.shape(valX), \"Y:\", np.shape(valY))\n",
        "print(\"Test:\", \"X:\", np.shape(testX), \"Y:\", np.shape(testY))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHi-DJUkpQzq"
      },
      "source": [
        "# **Exercise 1: Implementing Naive Bayes Classifier for Text Data to categorize news items**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4J6rGLXbpQzq"
      },
      "outputs": [],
      "source": [
        "def fit_nb(dataX, dataY):\n",
        "    output={}\n",
        "    output[\"data_total\"]=len(dataY)\n",
        "    labels=set(dataY)\n",
        "    for label_curr in labels:    #class label\n",
        "        output[label_curr]={}\n",
        "        current_rows=(dataY==label_curr)\n",
        "        dataX_curr=dataX[current_rows]\n",
        "        word_count=0\n",
        "        for i in range(len(word_list)):\n",
        "            output[label_curr][word_list[i]]=dataX_curr[:,i].sum()\n",
        "            word_count+=dataX_curr[:,i].sum()\n",
        "        output[label_curr][\"word_total\"]=word_count\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WR35yDOpQzr"
      },
      "outputs": [],
      "source": [
        "def log_prob(x, dict_train, class_curr):\n",
        "    output=np.log(dict_train[class_curr][\"word_total\"])-np.log(dict_train[\"data_total\"])\n",
        "    for i in range(len(word_list)):\n",
        "        current_word_count=dict_train[class_curr][word_list[i]]+1\n",
        "        total_word_count=dict_train[class_curr][\"word_total\"]+len(word_list)\n",
        "        current_word_probability=np.log(current_word_count)-np.log(total_word_count)\n",
        "        for j in range(int(x[i])):\n",
        "            output+=current_word_probability\n",
        "    return output\n",
        "\n",
        "\n",
        "def pred_doc(x, dict_train):\n",
        "    class_best=-1\n",
        "    prob_best=-1\n",
        "    class_all=dict_train.keys()\n",
        "    cond_exc=True\n",
        "    for class_curr in class_all:\n",
        "        if class_curr==\"data_total\":\n",
        "            continue\n",
        "        prob_class_curr=log_prob(x,dict_train,class_curr)\n",
        "        if(cond_exc==True or prob_class_curr>prob_best):\n",
        "            class_best=class_curr\n",
        "            prob_best=prob_class_curr\n",
        "        cond_exc=False\n",
        "    return class_best\n",
        "\n",
        "\n",
        "def pred_target(testX, dict_train):\n",
        "    pred_y=[]\n",
        "    num = 0\n",
        "    for x in testX:\n",
        "        pred_y.append(pred_doc(x, dict_train))\n",
        "    return pred_y\n",
        "\n",
        "\n",
        "def score(pred_y, trueY):      #mean accuracy\n",
        "    count = 0\n",
        "    for i in range(len(pred_y)):\n",
        "        if pred_y[i] == trueY[i]:\n",
        "            count+=1\n",
        "    return count/len(pred_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5s1kQXYpQzr"
      },
      "outputs": [],
      "source": [
        "predictions_dict=fit_nb(trainX,trainY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hrDf3DspQzr"
      },
      "outputs": [],
      "source": [
        "predY=pred_target(testX,predictions_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzyFCvq5pQzr",
        "outputId": "2660bd7e-7a35-4d89-e539-20d257967e7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bayesian test_accuracy= 0.98\n"
          ]
        }
      ],
      "source": [
        "test_accuracy = score(predY, testY)\n",
        "print(\"Bayesian test_accuracy=\", test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0Bp6GodpQzs"
      },
      "source": [
        "# **Exercise 2: Implementing SVM Classifier via Scikit-Learn by tuning the different SVM kernel**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yMBDq-WpQzs"
      },
      "source": [
        "##### Different SVM kernel choices are: 'rbf','poly','sigmoid','linear' within SVM classification choises of SVC, NuSVC and LinearSVC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRWOt2zjpQzs"
      },
      "source": [
        "## SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amDhaNi2pQzs"
      },
      "outputs": [],
      "source": [
        "#Hyperparameter selections\n",
        "C_list = [1, 10, 20, 50]  #Regularization parameter\n",
        "kernels_list = ['rbf','poly','sigmoid','linear']    #SVC kernels\n",
        "gamma_list = ['scale', 'auto']\n",
        "decisionfs_list = ['ovo', 'ovr']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0ecASvwpQzs"
      },
      "outputs": [],
      "source": [
        "hyperparameter_list = pd.DataFrame(columns=[\"C\", \"decision_function_shape\", \"gamma\", \"kernel\"])\n",
        "val_scores = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hctI3VgZpQzs",
        "outputId": "a462ab9a-72b7-4011-9d73-5f3997c5995e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'C': 10, 'decision_function_shape': 'ovo', 'gamma': 'auto', 'kernel': 'rbf'}\n",
            "0.94\n",
            "{'C': 10, 'decision_function_shape': 'ovo', 'gamma': 'scale', 'kernel': 'poly'}\n",
            "0.63\n",
            "{'C': 10, 'decision_function_shape': 'ovo', 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
            "0.945\n",
            "{'C': 1, 'decision_function_shape': 'ovo', 'gamma': 'scale', 'kernel': 'linear'}\n",
            "0.945\n"
          ]
        }
      ],
      "source": [
        "for k in kernels_list:\n",
        "    svc_lib = SVC()\n",
        "    parameters={'C': C_list, 'kernel': [k], 'gamma': gamma_list , 'decision_function_shape': decisionfs_list}\n",
        "    \n",
        "    grid_search = GridSearchCV(svc_lib, parameters, n_jobs = -1, cv = 3)\n",
        "    grid_search.fit(valX,valY)    \n",
        "    print(grid_search.best_params_)\n",
        "    print(grid_search.best_score_)\n",
        "    \n",
        "    hyperparameter_list = hyperparameter_list.append(grid_search.best_params_, ignore_index=True)\n",
        "    val_scores.append(grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkZDb3kupQzt",
        "outputId": "238cf7c3-e432-49f9-d9f4-ca73250fa65b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>C</th>\n",
              "      <th>decision_function_shape</th>\n",
              "      <th>gamma</th>\n",
              "      <th>kernel</th>\n",
              "      <th>val_scores</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>ovo</td>\n",
              "      <td>auto</td>\n",
              "      <td>rbf</td>\n",
              "      <td>0.940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>ovo</td>\n",
              "      <td>scale</td>\n",
              "      <td>poly</td>\n",
              "      <td>0.630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10</td>\n",
              "      <td>ovo</td>\n",
              "      <td>scale</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>0.945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>ovo</td>\n",
              "      <td>scale</td>\n",
              "      <td>linear</td>\n",
              "      <td>0.945</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    C decision_function_shape  gamma   kernel  val_scores\n",
              "0  10                     ovo   auto      rbf       0.940\n",
              "1  10                     ovo  scale     poly       0.630\n",
              "2  10                     ovo  scale  sigmoid       0.945\n",
              "3   1                     ovo  scale   linear       0.945"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hyperparameter_list[\"val_scores\"] = val_scores\n",
        "hyperparameter_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iA_xMQyfpQzt"
      },
      "outputs": [],
      "source": [
        "hyperparameter_list = hyperparameter_list.drop(['val_scores'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dt0FbPZMpQzt",
        "outputId": "f9876a11-136e-4e82-a130-9847ee316cd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy Scores given SVC kernels with their best hyperparamaters\n",
            "For Kernel= rbf\n",
            "Test accuracy is= 0.975\n",
            "For Kernel= poly\n",
            "Test accuracy is= 0.87\n",
            "For Kernel= sigmoid\n",
            "Test accuracy is= 0.975\n",
            "For Kernel= linear\n",
            "Test accuracy is= 0.98\n"
          ]
        }
      ],
      "source": [
        "print(\"Test Accuracy Scores given SVC kernels with their best hyperparamaters\")\n",
        "test_accuracy_scores = []\n",
        "\n",
        "for i in range(len(hyperparameter_list)):\n",
        "    print(\"For Kernel=\",hyperparameter_list.iloc[i][3])    #SVM kernel choice\n",
        "    clf = SVC(C=hyperparameter_list.iloc[i][0],decision_function_shape=hyperparameter_list.iloc[i][1],gamma=hyperparameter_list.iloc[i][2],kernel=hyperparameter_list.iloc[i][3])\n",
        "    clf.fit(trainX, trainY)\n",
        "    acc = clf.score(testX,testY)      #report test accuracy\n",
        "    print(\"Test accuracy is=\", acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_gOV79jpQzt"
      },
      "outputs": [],
      "source": [
        "#Looking at the best accuracy score in gridsearch: best hyperparameter option is as follows /Extra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EyilFMm5pQzt",
        "outputId": "2dfdb65f-9ac9-4ce6-e414-e1b330e0fc36"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>C</th>\n",
              "      <th>decision_function_shape</th>\n",
              "      <th>gamma</th>\n",
              "      <th>kernel</th>\n",
              "      <th>val_scores</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>ovo</td>\n",
              "      <td>auto</td>\n",
              "      <td>rbf</td>\n",
              "      <td>0.940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>ovo</td>\n",
              "      <td>scale</td>\n",
              "      <td>poly</td>\n",
              "      <td>0.630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10</td>\n",
              "      <td>ovo</td>\n",
              "      <td>scale</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>0.945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>ovo</td>\n",
              "      <td>scale</td>\n",
              "      <td>linear</td>\n",
              "      <td>0.945</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    C decision_function_shape  gamma   kernel  val_scores\n",
              "0  10                     ovo   auto      rbf       0.940\n",
              "1  10                     ovo  scale     poly       0.630\n",
              "2  10                     ovo  scale  sigmoid       0.945\n",
              "3   1                     ovo  scale   linear       0.945"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hyperparameter_list[\"val_scores\"] = val_scores\n",
        "hyperparameter_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-PcRUMypQzt",
        "outputId": "043cb47c-3f04-4fbb-9360-57737f962881"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best hyperparameters:\n",
            " C                               10\n",
            "decision_function_shape        ovo\n",
            "gamma                        scale\n",
            "kernel                     sigmoid\n",
            "val_scores                   0.945\n",
            "Name: 2, dtype: object\n"
          ]
        }
      ],
      "source": [
        "params_best=hyperparameter_list.iloc[np.argmax(hyperparameter_list.val_scores),:] #find best hyperparameters according to highest accuracy\n",
        "print(\"Best hyperparameters:\\n\", params_best)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqJ2-N94pQzu"
      },
      "outputs": [],
      "source": [
        "#Fitting these best hyperparameters to SVM classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wp7QSuwpQzu",
        "outputId": "f174a393-e40e-485e-9f8f-08028264bd28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test data accuracy using best hyperparameters found from validation is=  0.975\n"
          ]
        }
      ],
      "source": [
        "clf = SVC(C=params_best[0],decision_function_shape=params_best[1],gamma=params_best[2],kernel=params_best[3])\n",
        "clf.fit(trainX, trainY)   #train data to fit model\n",
        "best_hyp_score = clf.score(testX,testY)\n",
        "print(\"Test data accuracy using best hyperparameters found from validation is= \",best_hyp_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7w3zFN-pQzu"
      },
      "source": [
        "## NuSVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zwpbE6UpQzu"
      },
      "outputs": [],
      "source": [
        "nu_list = [0.1, 0.5, 0.9]\n",
        "kernels_list = ['rbf','poly','sigmoid','linear']    #SVC kernels\n",
        "gamma_list = ['scale', 'auto']\n",
        "decisionfs_list = ['ovo', 'ovr']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYOWAr4XpQzu"
      },
      "outputs": [],
      "source": [
        "hyperparameter_list2 = pd.DataFrame(columns=[\"nu\", \"decision_function_shape\", \"gamma\", \"kernel\"])\n",
        "val_scores = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xzc0SRYWpQzv",
        "outputId": "012c675b-892d-4000-c422-f59afeff369d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'decision_function_shape': 'ovo', 'gamma': 'auto', 'kernel': 'rbf', 'nu': 0.1}\n",
            "0.94\n",
            "{'decision_function_shape': 'ovo', 'gamma': 'scale', 'kernel': 'poly', 'nu': 0.1}\n",
            "0.63\n",
            "{'decision_function_shape': 'ovo', 'gamma': 'scale', 'kernel': 'sigmoid', 'nu': 0.1}\n",
            "0.945\n",
            "{'decision_function_shape': 'ovo', 'gamma': 'scale', 'kernel': 'linear', 'nu': 0.1}\n",
            "0.945\n"
          ]
        }
      ],
      "source": [
        "for k in kernels_list:\n",
        "    svc_lib = NuSVC()\n",
        "    parameters={'nu': nu_list, 'kernel': [k], 'gamma': gamma_list , 'decision_function_shape': decisionfs_list}\n",
        "    \n",
        "    grid_search2 = GridSearchCV(svc_lib, parameters, n_jobs = -1, cv = 3)\n",
        "    grid_search2.fit(valX,valY)    \n",
        "    print(grid_search2.best_params_)\n",
        "    print(grid_search2.best_score_)\n",
        "    \n",
        "    hyperparameter_list2 = hyperparameter_list2.append(grid_search2.best_params_, ignore_index=True)\n",
        "    val_scores.append(grid_search2.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBsg5DfMpQzv",
        "outputId": "15d66fe6-a108-4f18-9ffd-f7bff569bbfb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nu</th>\n",
              "      <th>decision_function_shape</th>\n",
              "      <th>gamma</th>\n",
              "      <th>kernel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.1</td>\n",
              "      <td>ovo</td>\n",
              "      <td>auto</td>\n",
              "      <td>rbf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.1</td>\n",
              "      <td>ovo</td>\n",
              "      <td>scale</td>\n",
              "      <td>poly</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.1</td>\n",
              "      <td>ovo</td>\n",
              "      <td>scale</td>\n",
              "      <td>sigmoid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.1</td>\n",
              "      <td>ovo</td>\n",
              "      <td>scale</td>\n",
              "      <td>linear</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    nu decision_function_shape  gamma   kernel\n",
              "0  0.1                     ovo   auto      rbf\n",
              "1  0.1                     ovo  scale     poly\n",
              "2  0.1                     ovo  scale  sigmoid\n",
              "3  0.1                     ovo  scale   linear"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hyperparameter_list2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3VMHNIrpQzv",
        "outputId": "52e5c73d-9575-4e13-c6bb-ff2937cfd26b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy Scores given NuSVC kernels with their best hyperparamaters\n",
            "For Kernel= rbf\n",
            "Test accuracy is= 0.975\n",
            "For Kernel= poly\n",
            "Test accuracy is= 0.87\n",
            "For Kernel= sigmoid\n",
            "Test accuracy is= 0.975\n",
            "For Kernel= linear\n",
            "Test accuracy is= 0.98\n"
          ]
        }
      ],
      "source": [
        "print(\"Test Accuracy Scores given NuSVC kernels with their best hyperparamaters\")\n",
        "test_accuracy_scores = []\n",
        "\n",
        "for i in range(len(hyperparameter_list2)):\n",
        "    print(\"For Kernel=\",hyperparameter_list2.iloc[i][3])    #SVM kernel choice\n",
        "    clf = NuSVC(nu=hyperparameter_list2.iloc[i][0],decision_function_shape=hyperparameter_list2.iloc[i][1],gamma=hyperparameter_list2.iloc[i][2],kernel=hyperparameter_list2.iloc[i][3])\n",
        "    clf.fit(trainX, trainY)\n",
        "    acc = clf.score(testX,testY)      #report test accuracy\n",
        "    print(\"Test accuracy is=\", acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ubf9U0-pQzv"
      },
      "source": [
        "## LinearSVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q27x8r4QpQzv"
      },
      "outputs": [],
      "source": [
        "penalty_list = ['l2']     #l1 couldnt add because it is not supported with hinge loss\n",
        "kernels_list = ['linear']    #Only Linear is available\n",
        "loss_list = ['hinge','squared_hinge']\n",
        "C_list = [1, 10, 20, 50]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lh4vZmSNpQzv"
      },
      "outputs": [],
      "source": [
        "hyperparameter_list3 = pd.DataFrame(columns=[\"penalty\", \"loss\", \"C\"])\n",
        "val_scores = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrXlFDF1pQzw",
        "outputId": "c8307a09-7afc-4ff3-c1c5-29c70dab90ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'C': 1, 'loss': 'hinge', 'penalty': 'l2'}\n",
            "0.95\n"
          ]
        }
      ],
      "source": [
        "svc_lib = LinearSVC()\n",
        "parameters={'penalty': penalty_list, 'loss': loss_list , 'C': C_list}\n",
        "    \n",
        "grid_search3 = GridSearchCV(svc_lib, parameters, n_jobs = -1, cv = 3)\n",
        "grid_search3.fit(valX,valY)    \n",
        "print(grid_search3.best_params_)\n",
        "print(grid_search3.best_score_)\n",
        "    \n",
        "hyperparameter_list3 = hyperparameter_list3.append(grid_search3.best_params_, ignore_index=True)\n",
        "val_scores.append(grid_search3.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uA1IajNhpQzw",
        "outputId": "8e5fbaf6-90c7-4278-ce1d-dc0b7c1cca6a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>penalty</th>\n",
              "      <th>loss</th>\n",
              "      <th>C</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>l2</td>\n",
              "      <td>hinge</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  penalty   loss  C\n",
              "0      l2  hinge  1"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hyperparameter_list3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-F0BbNv1pQzw",
        "outputId": "44fd873f-8385-4684-a09d-c36e9b32737c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy Scores given LinearSVC kernels with their best hyperparamaters\n",
            "For Kernel = Linear\n",
            "Test accuracy is= 0.975\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ]
        }
      ],
      "source": [
        "print(\"Test Accuracy Scores given LinearSVC kernels with their best hyperparamaters\")\n",
        "test_accuracy_scores = []\n",
        "\n",
        "for i in range(len(hyperparameter_list3)):\n",
        "    print(\"For Kernel = Linear\")    #LinearSVC only allows linear kernel\n",
        "    clf = LinearSVC(penalty=hyperparameter_list3.iloc[i][0],loss=hyperparameter_list3.iloc[i][1], C=hyperparameter_list3.iloc[i][2])\n",
        "    clf.fit(trainX, trainY)\n",
        "    acc = clf.score(testX,testY)      #report test accuracy\n",
        "    print(\"Test accuracy is=\", acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiJmFlPmpQzx"
      },
      "source": [
        "##### Explanation: Given 3 types of SVM classifiers (SVC, NuSVC, LinearSVC), using kernels rbf, polynomial, sigmoid and linear gives similar results. Linear, sigmoid and rbf kernels performed well on validation and test accuracy, while polynomial kernel not performed that well. Fitting data is fastest in SVC. Note: LinearSVC only allowed linear kernel."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zjwXq1KpQzx"
      },
      "source": [
        "# References\n",
        "\n",
        "###https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html\n",
        "###https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html#training-a-classifier\n",
        "###https://towardsdatascience.com/natural-language-processing-feature-engineering-using-tf-idf-e8b9d00e7e76\n",
        "###https://towardsdatascience.com/implementing-a-naive-bayes-classifier-for-text-categorization-in-five-steps-f9192cdd54c3\n",
        "###https://github.com/jonhare/LloydsRegistryMachineLearningCourse/blob/master/Monday/ml101-tutorial/tutorial.md\n",
        "###https://stackoverflow.com/questions/23289547/shuffle-two-list-at-once-with-same-order\n",
        "###https://github.com/gokriznastic/20-newsgroups_text-classification/blob/master/Multinomial%20Naive%20Bayes-%20BOW%20with%20TF.ipynb\n",
        "###https://scikit-learn.org/stable/modules/svm.html\n",
        "###https://machinelearningmastery.com/scikit-optimize-for-hyperparameter-tuning-in-machine-learning/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "93i4wzPNrOwe"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "NLPClassification_NaiveBayes&SVM.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "z7w3zFN-pQzu",
        "-ubf9U0-pQzv"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}