# Machine Learning Practical

### Python Basics and Simple Linear Regression Task        [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1SYv6Fmp_jv9G2jU0biRVyOig2RqjDLS2?usp=sharing)
- IPython Basics
- Image blurring program using numpy matrices
- implementing Linear Regresssion model and making predictions

### Word Count Program and Linear Regression 
- Build word count program
- Matrix Multiplication with Numpy library
- Linear Regression with defined matrices

### Exploratory Analysis and Multiple Linear Regression
- Investigate real world dataset using Pandas and Matplotlib libraries
- Implement Multiple Linear Regression for 10 features using Gaussian Elemination and forecasting future sales for next 42 days

### Linear Regression with Gradient Descent and Steplength Control
- Optimize Rosenbrock function with Gradient descent
- Preprocess 3 datasets fro regression task and implement linear regression algorithm with gradient descent
- Implement step-length controlling algorithms

### Logistic Regression with Gradient Descent and Newton Algorithm
- Dataset (tic-tac-toe) preprocessing for classification task
- Implement logistic regression with stochastic gradient descent algorithm
- Implement logistic regression with Newton algorithm

### Backward search for variable selection and Regularization for Logistic Regression
- Implement logistic regression and mini-batch Gradient ascent and use backward search procedure with regard to the AIC metric
- Implement grid search with k-fold cross-validation with extending model with regularization

### Generalized Linear Models with Scikit Learn and Coordinate Descent
- Generate and preprocess datasets for regressions tasks
- Ordinary Least Squares with Stochastic gradient descent (SGD)
- Ridge Regression with Stochastic gradient descent (SGD)
- LASSO with Stochastic gradient descent (SGD)
- Hyperparameter tuning with GridSearchCV
- Prediction with high degree of polynomials and analyzing the effect of regularization
- Implementing Lasso Regression with Coordinate Descent with/out regularization

### Neural Network model for Classification task
- Classify human-written digits into either of the first 10 using MNIST dataset
- Implement k-cross fold validation and hyperparameter optimization with Random Search

### Decision Tree and Gradient Boosted Decision Trees
- Build a decision tree for classification
- Quality criterion as Misclassification Rate (MCR) and Information Gain (IG)
- Build a Gradient Boosted Decision Tree Classifier for a binary classification task

### Exploring Movie Recommendation Dataset and Matrix factorization (MF) technique for recommender systems
- Explore Movielens 100k Dataset
- Implementing Stochastic Gradient Descent (SGD) to solve Matrix Factorization problem and compute RMSE
- Learn a matrix factorization model using coordinate descent method and optimize the hyperparameters and perform a 3-fold cross validation

### Naive Bayes Classifier and Support Vector Machines for Text Data
- Preprocess 20newsgroups dataset (A collection of 20,000 news items across 20 categories) for text classification task
- Implementing a Naive Bayes Classifier to categorize news items and report test accuracy
- Implementing SVM Classifier via Scikit-Learn and report test accuracy
